name: "AOTP EvalGate"
description: "Run deterministic LLM/RAG evals as a PR check"
author: "AOTP Ventures"
branding: { icon: "check-square", color: "blue" }

inputs:
  config:
    description: "Path to evalgate YAML config"
    required: true
  openai_api_key:
    description: "OpenAI API key for LLM evaluators (optional)"
    required: false
  anthropic_api_key:
    description: "Anthropic API key for LLM evaluators (optional)"
    required: false
  azure_api_key:
    description: "Azure API key for LLM evaluators (optional)"
    required: false
  check_run:
    description: "Create a GitHub check run with results (optional)"
    required: false
    default: "false"

outputs:
  total_score:
    description: "Overall score from .evalgate/results.json"
    value: ${{ steps.results.outputs.total_score }}
  passed:
    description: "Whether EvalGate passed"
    value: ${{ steps.results.outputs.passed }}

runs:
  using: "composite"
  steps:
    - name: Install uv
      shell: bash
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.local/bin" >> $GITHUB_PATH
    - name: Cache LLM responses
      uses: actions/cache@v4
      with:
        path: .evalgate/cache.json
        key: ${{ runner.os }}-evalgate-${{ hashFiles('.evalgate/cache.json') }}
        restore-keys: ${{ runner.os }}-evalgate-
    - name: Run EvalGate (PyPI)
      shell: bash
      env:
        OPENAI_API_KEY: ${{ inputs.openai_api_key }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic_api_key }}
        AZURE_API_KEY: ${{ inputs.azure_api_key }}
      run: |
        uvx --from evalgate[llm] evalgate run --config "${{ inputs.config }}"
    - name: Read Results
      id: results
      if: always()
      shell: bash
      run: |
        total_score=$(jq -r '.overall' .evalgate/results.json)
        passed=$(jq -r '.gate.passed' .evalgate/results.json)
        echo "total_score=$total_score" >> "$GITHUB_OUTPUT"
        echo "passed=$passed" >> "$GITHUB_OUTPUT"
    - name: Summary
      if: always()
      shell: bash
      run: |
        args="--summary --artifact ./.evalgate/results.json"
        if [[ "${{ inputs.check_run }}" == "true" ]]; then
          args="$args --check-run"
        fi
        uvx --from evalgate evalgate report $args
    - name: Upload Results Artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: evalgate-results
        path: .evalgate/results.json
        retention-days: 30
