# EvalGate v0.2.0 - Legacy Documentation

**EvalGate v0.2.0** is an open-source tool that runs deterministic LLM/RAG evaluations as GitHub PR checks. This version focuses on core deterministic evaluations.

## Quick Start

### Installation
```bash
# Initialize EvalGate in your project
uvx --from evalgate evalgate init

# Generate your model's outputs
python scripts/predict.py --in eval/fixtures --out .evalgate/outputs

# Run evaluation
uvx --from evalgate evalgate run --config .github/evalgate.yml
```

### GitHub Actions Integration
```yaml
name: EvalGate
on: [pull_request]

jobs:
  evalgate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Generate outputs
        run: python scripts/predict.py --in eval/fixtures --out .evalgate/outputs
      - uses: aotp-ventures/evalgate@v0.2.0
        with:
          config: .github/evalgate.yml
          check_run: true
```

## Configuration (v0.2.0)

Basic YAML configuration:

```yaml
budgets:
  p95_latency_ms: 1200
  max_cost_usd_per_item: 0.03

fixtures:
  path: "eval/fixtures/**/*.json"
outputs:
  path: ".evalgate/outputs/**/*.json"

evaluators:
  - name: json_formatting
    type: json_schema
    schema_path: "eval/schemas/response.json"
    weight: 0.4
  
  - name: priority_accuracy
    type: category_match
    expected_field: "priority"
    weight: 0.4
  
  - name: latency_cost
    type: latency_cost
    weight: 0.2

gate:
  min_overall_score: 0.90
  allow_regression: false

report:
  pr_comment: true
  artifact_path: ".evalgate/results.json"
baseline:
  ref: "origin/main"
```

## Core Evaluator Types (v0.2.0)

### json_schema
Validates JSON structure:
```yaml
- name: schema_check
  type: json_schema
  schema_path: "eval/schemas/output.json"
  weight: 0.4
```

### category_match  
Checks categorical fields:
```yaml
- name: category_check
  type: category_match
  expected_field: "category" 
  weight: 0.4
```

### latency_cost
Performance validation:
```yaml
- name: performance_check
  type: latency_cost
  weight: 0.2
```

## CLI Commands (v0.2.0)

```bash
# Initialize project
uvx --from evalgate evalgate init

# Run evaluation
uvx --from evalgate evalgate run --config .github/evalgate.yml

# Generate report
uvx --from evalgate evalgate report --summary --artifact .evalgate/results.json

# Update baseline
uvx --from evalgate evalgate baseline update --config .github/evalgate.yml
```

## Fixture Format (v0.2.0)

```json
{
  "input": {
    "message": "Customer support request"
  },
  "expected": {
    "priority": "medium",
    "category": "support"
  },
  "meta": {
    "latency_ms": 800,
    "cost_usd": 0.02
  }
}
```

## Output Format (v0.2.0)

```json
{
  "priority": "medium",
  "category": "support",
  "response": "We'll help you with that",
  "confidence": 0.9
}
```

## Upgrade to v0.3.0

EvalGate v0.3.0 adds many new features:

- **13+ evaluator types** (v0.2.0 has 3)
- **LLM judge support** (OpenAI, Anthropic, local models)
- **Conversation fixtures** for multi-turn dialogue
- **Tool usage validation** for AI agents
- **Embedding similarity** for semantic matching
- **Text similarity** (ROUGE, BLEU scores)
- **Classification metrics** (precision, recall, F1)
- **Workflow DAG validation** for complex processes
- **Enhanced GitHub Actions** integration
- **Better error handling** and debugging

To upgrade:
```bash
# Update to latest version
uvx --from evalgate evalgate --help

# Review new configuration options
uvx --from evalgate evalgate validate --config .github/evalgate.yml
```

## Repository and Support

- **License:** MIT
- **Repository:** https://github.com/aotp-ventures/evalgate  
- **Issues:** https://github.com/aotp-ventures/evalgate/issues
- **Documentation:** https://evalgate.aotp.ai

For the latest features, please upgrade to v0.3.0 or later.
